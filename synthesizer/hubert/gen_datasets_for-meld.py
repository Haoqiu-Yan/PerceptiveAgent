"""
CHANGE FROM: code/synthesis/hubert/gen_datasets.py
构造meld输入
---
LOCATION: /data1/haoqiuyan/ws_iwslt/code/parse_hubert_codes_zh.py (1702)

为训练vocoder准备数据集,
把unit codes, response labels, manifest文件组合在一起, 
新生成的文件形式为
{'audio': path, 'hubert': XX, 'duration': xx, \
'spk': xx, 'style': xx, 'pitch': xx, 'speed': xx, 'energy': ,}

from: speech-resynthesis/scripts/parse_hubert_codes.py
modified by haoqiu

------
Usage:

python code/synthesis/hubert/gen_datasets_for-meld.py  --codes ./framework/t2u/ours/translation/path_units.txt --id-path ./framework/meld/id_paths.txt --labels ./framework/labeling/ours/response/0127-1330pm/labels_cleaned_all.json --saveas ./framework/synthesis/ours/input.txt

"""


import os
import json
import argparse
import random
from pathlib import Path
import pandas as pd

from tqdm import tqdm


def read_codes(codes_file):
    with open(codes_file) as cf:
        fname_code = {l.split('\t')[0]:l.split('\t')[1].strip() for l in cf.readlines()}
    codesDF = pd.DataFrame.from_dict(fname_code, orient='index', columns=[ 'hubert'])
    codesDF.index.name = 'audiopath'
        
    return codesDF


def read_id_path(audiopath_file):
    with open(audiopath_file, 'r') as af:
        pathsL = [line.strip() for line in af]
    # pathsD = {'audiopath': pathsL}
    # pathDF = pd.DataFrame.from_dict(pathsD)

    # return pathDF
    return pathsL


def read_labels(json_file):
    with open(json_file, encoding='utf-8') as jf:
        samplesL = [json.loads(l) for l in jf.readlines() if l != '\n']
    columns = samplesL[0].keys()
    attributesD = {k:[] for k in columns}
    for sample in samplesL:
        if sample.keys() != columns:
            print(f"[INFO] read_labels SKIP {sample}")
            continue
        if None in sample.values():
            # '{"id": null}'
            print(f"[INFO] read_labels SKIP {sample}")
            continue

        for k in attributesD.keys():
            attributesD[k].append(sample[k])
        
    predDF = pd.DataFrame(attributesD)
    predDF = predDF.rename(columns={"emotion":"style"})
    # 保留id列
    # predDF.set_index('id', inplace=True, drop=False)

    return predDF


def merge_to_labels(labelsDF, codesDF, durDF):
    mergedDF = labelsDF.set_index('name').join(codesDF)
    mergedDF = mergedDF.join(durDF)

    unmatchDF = mergedDF[mergedDF.isna().any(axis=1)]
    if not unmatchDF.empty:
        print(f"[INFO] unmatchDF:\n{unmatchDF}")

    selected_columns = ['audio', 'hubert', 'duration', 'spk', 'style', \
                        'pitch', 'speed', 'energy',]
    
    return mergedDF[selected_columns]


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--codes', type=Path, required=True, help='File of units, eg: fname<tab>49 1')
    parser.add_argument('--labels', type=Path, required=True, help='File of labels generated by chatGPT, eg(csv file): {id:}')
    parser.add_argument('--id-path', type=Path, required=True, help='File that contains all audios, with frame numbers')
    parser.add_argument('--saveas', type=Path, required=True)
    
    args = parser.parse_args()

    codesDF = read_codes(args.codes)
    pathsL = read_id_path(args.id_path)
    labelsDF = read_labels(args.labels)

    # labelsDF starts from 1, while pathsL starts from 0.
    labelsDF['audiopath'] = labelsDF['id'].map(lambda x:pathsL[int(x)-1])
    mergedDF = labelsDF.set_index('audiopath').join(codesDF)

    # 随机指定spk
    mergedDF['spk'] = 'ex01'
    mergedDF['audio'] = mergedDF['id'].map(lambda x:f"{x}_id")

    print(mergedDF.columns)
    mergedD = mergedDF.to_dict('records')

    save_file = os.path.join(args.saveas)
    with open(save_file, 'w') as of:
        for sample in mergedD:
            print(sample, file=of)
    print(f"Writing to {save_file}")


if __name__ == '__main__':
    main()
