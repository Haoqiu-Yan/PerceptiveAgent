"""
LOCATION: /data1/haoqiuyan/ws_iwslt/code/parse_hubert_codes_zh.py (1702)

为训练vocoder准备数据集,
把unit codes, response labels, manifest文件组合在一起, 
新生成的文件形式为
{'audio': path, 'hubert': XX, 'duration': xx, \
'spk': xx, 'style': xx, 'pitch': xx, 'speed': xx, 'energy': ,}

from: speech-resynthesis/scripts/parse_hubert_codes.py
modified by haoqiu

------
Usage:

python code/synthesis/hubert/gen_datasets.py  --codes ./speech_synthesis/hubert_kmn_getcodes/transcript.units --manifest ./speech_synthesis/hubert_kmn_getcodes/manifest/manifest_all.tsv --labels ./speech_synthesis/open_api_getlabels/expresso/splits-read/dev_labeled_read-only.csv --outdir speech_synthesis/gen_dateset_codes_with_labels --split dev_read-only


"""


import os
import argparse
import random
from pathlib import Path
import pandas as pd

from tqdm import tqdm


def read_codes(codes_file):
    with open(codes_file) as cf:
        fname_code = {l.split('\t')[0]:l.split('\t')[1].strip() for l in cf.readlines()}
    codesDF = pd.DataFrame.from_dict(fname_code, orient='index', columns=[ 'hubert'])
    codesDF.index.name = 'name'
        
    return codesDF


def read_manifest(m_file):
    with open(m_file) as mf:
        audio_root = Path(mf.readline())
        fname_dur = {l.split('\t')[0].split('.wav')[0]:l.split('\t')[1].strip() for l in mf.readlines()}
    durDF = pd.DataFrame.from_dict(fname_dur, orient='index', columns=[ 'duration'])
    # add without test
    durDF['duration'] = durDF['duration'].apply(lambda x:int(x) / 16000)
    durDF.index.name = 'name'

    return durDF


def read_labels(labels_file):
    labelsDF = pd.read_csv(labels_file)
    labelsDF['audio'] = labelsDF['audio'].apply(lambda x:x.replace('merge_audio_48khz', 'merge_audio_16khz'))

    # 有些labels是空值, 补全
    return labelsDF.fillna(value='normal')


def merge_to_labels(labelsDF, codesDF, durDF):
    mergedDF = labelsDF.set_index('name').join(codesDF)
    mergedDF = mergedDF.join(durDF)

    unmatchDF = mergedDF[mergedDF.isna().any(axis=1)]
    if not unmatchDF.empty:
        print(f"[INFO] unmatchDF:\n{unmatchDF}")

    selected_columns = ['audio', 'hubert', 'duration', 'spk', 'style', \
                        'pitch', 'speed', 'energy',]
    
    return mergedDF[selected_columns]


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--codes', type=Path, required=True, help='File of units, eg: fname<tab>49 1')
    parser.add_argument('--labels', type=Path, required=True, help='File of labels generated by chatGPT, eg(csv file): ,id,gender,pitch,speed,energy,chat_style,audio,name,spk,style')
    parser.add_argument('--manifest', type=Path, required=True, help='File that contains all audios, with frame numbers')
    parser.add_argument('--outdir', type=Path, required=True)
    parser.add_argument('--split', type=str, default='all', help='saved file name')
    
    args = parser.parse_args()

    codesDF = read_codes(args.codes)
    durDF = read_manifest(args.manifest)
    labelsDF = read_labels(args.labels)

    mergedDF = merge_to_labels(labelsDF, codesDF, durDF)
    mergedD = mergedDF.to_dict('records')

    save_file = os.path.join(args.outdir, args.split+'.txt')
    with open(save_file, 'w') as of:
        for sample in mergedD:
            print(sample, file=of)
    print(f"Writing to {save_file}")


if __name__ == '__main__':
    main()
